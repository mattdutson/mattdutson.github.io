---
title: Thoughts on Ethical Research
layout: default
---

# Thoughts on Ethical Research

Questions about the potential negative impacts of my research have recently been weighing on my mind. Joseph Redmon, a prominent researcher, recently paused his computer vision research over worries about surveillance and misuse by the military. I share his concerns. Many 21st century ailments - political division, consumerism, technology addiction, and surveillance - can be traced to the large-scale manipulation of humans by artificial agents.

These realities are in stark contrast to the vision of AI that I (and others in the field) hold in our minds. In the long term, artificial intelligence has the potential to liberate humanity from its physical constraints. In the near term, AI promises (among other things) to give us more accurate cancer diagnoses, reduce traffic fatalities, and fuel new scientific advancements.

Regardless of the outcome, artificial intelligence will make human beings more powerful. But, it will not make us wiser. For wisdom, we have only the old tools: leadership, persuasion, and education.

I am not a great leader or a persuasive speaker. I may eventually have a role in education, cultivating a generation of better, more responsible technologists. But the danger is now, not a generation away. My current obligation is individual leadership - to add my small weight to the cause of the humans.

The first half of this responsibility is political - using my position in a democratic society to advocate for systemic change. The second half is individual - prudently directing my talents and vigorously guarding against their misappropriation.

Research lies on a continuum of specificity. On the left is basic research: physics, mathematics, and computing theory. On the right are purpose-built technologies: facial recognition algorithms, self-driving cars, and social media apps.

The responsibility of a researcher increases toward the right end of the spectrum. Alan Turing is not morally culpable for abuses of computers and the internet. However, researchers who build facial recognition technology know full well that their work has many questionable applications. The more specific a technology, the more information we have about its potential uses and misuses. This knowledge imparts a moral obligation to the researcher.

Our criteria should not be plausible deniability. Bad actors often hide dangerous technologies behind a veil of altruism. A system for tracking endangered animals in a national park can also be used to track dissidents at a political protest. The funding source often points to the dominant application. Research funded by authoritarian governments, the military, or surveillance capitalists should be carefully scrutinized.

For now, I choose to stay in this field because I love the work and still believe in the promise of AI. I strive to cultivate the courage and clarity to make wise decisions, even when they are difficult or disappointing.
